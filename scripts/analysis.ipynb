{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bitd171fe3837a649ac9d856f7ce482dbdd",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "\n",
    "from time import sleep\n",
    "from mido import MidiFile\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import date\n",
    "from time import time, monotonic\n",
    "from os import path, mkdir, listdir, environ\n",
    "import subprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Args, define evaluation groups\n",
    "\n",
    "iterations = 4        # How many times each experiment should be repeated for the same parameters?\n",
    "min_input_bars = 1    # What is the minimum lookback size for each model?\n",
    "min_output_bars = 1   # What is the minimum output size for each model?\n",
    "\n",
    "max_input_bars = 5    # What is the maximum lookback size for each model?\n",
    "max_output_bars = 5   # What is the maximum output size for each model?\n",
    "sample_length = 16    # How long of a final composition should be generated?\n",
    "ignore = (            # What models to ignore during generation/analysis\n",
    "  [ 'music_transformer'\n",
    "  # , 'rl_duet'            # FIXME: This is temporary because shit went wrong\n",
    "  # , 'pianoroll_rnn_nade' # FIXME: This is temporary because shit went wrong\n",
    "  ] \n",
    ")\n",
    "modelname = None\n",
    "checkpointname = None\n",
    "\n",
    "\n",
    "# FIXME: Remove this\n",
    "iterations = 1\n",
    "max_input_bars = 2\n",
    "max_output_bars = 2\n",
    "sample_length = 6\n",
    "\n",
    "\n",
    "# Evaluated Model Table\n",
    "eval_columns = (\n",
    "    ['model'               , 'dataset'       , 'output_tracks' , 'checkpoint']\n",
    ")\n",
    "eval_list = (\n",
    "  [ ['performance_rnn'     , 'piano-e-comp'  , None            , 'performance_with_dynamics']\n",
    "  , ['performance_rnn'     , 'piano-e-comp'  , None            , 'density_conditioned_performance_with_dynamics']\n",
    "  , ['performance_rnn'     , 'piano-e-comp'  , None            , 'pitch_conditioned_performance_with_dynamics']\n",
    "  , ['performance_rnn'     , 'piano-e-comp'  , None            , 'multiconditioned_performance_with_dynamics']\n",
    "  , ['performance_rnn'     , 'piano-e-comp'  , None            , 'performance_with_dynamics_and_modulo_encoding']\n",
    "  , ['rl_duet'             , 'bach10'        , None            , 'rl_duet']\n",
    "  , ['pianoroll_rnn_nade'  , 'bach10'        , None            , 'rnn-nade_attn']\n",
    "\n",
    "  # TODO: MelodyRNN \n",
    "  , ['melody_rnn'          , 'bach10'        , '1 2 3 4'       , 'basic_rnn']\n",
    "  , ['melody_rnn'          , 'bach10'        , '1 2 3 4'       , 'mono_rnn']\n",
    "  , ['melody_rnn'          , 'bach10'        , '1 2 3 4'       , 'attention_rnn']\n",
    "  , ['melody_rnn'          , 'bach10'        , '1 2 3 4'       , 'lookback_rnn']\n",
    "  , ['polyphony_rnn'       , 'bach10'        , None            , 'polyphony_rnn']\n",
    "  , ['pianoroll_rnn_nade'  , 'bach10'        , None            , 'rnn-nade_attn']\n",
    "  , ['music_transformer'   , 'piano-e-comp'  , None            , 'performance_with_dynamics']\n",
    "  ]\n",
    ")\n",
    "eval_list = pd.DataFrame(eval_list, columns=eval_columns)\n",
    "\n",
    "# Filter ignored models\n",
    "for ignored_model in ignore:\n",
    "  eval_list = eval_list[eval_list['model'] != ignored_model]\n",
    "\n",
    "# Index table with dataset names\n",
    "evaluation_sets = [\n",
    "  (dataset, [ (modelname, checkpoint, output_tracks)\n",
    "    for [modelname, checkpoint, output_tracks]\n",
    "    in inner_df[['model', 'checkpoint', 'output_tracks']].values \n",
    "  ])\n",
    "  for dataset, inner_df in eval_list.groupby(['dataset'])\n",
    "]\n",
    "\n",
    "cols_gen = [ \"model\", \"checkpoint\", \"dataset\", \"primer\", \"iteration\", \"out_file\", \"time\", \"in_len\", \"out_len\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder Definitions (+ Create new folder)\n",
    "outputdir = path.join(path.curdir,'output')\n",
    "datasetdir = path.join(path.curdir,'dataset')\n",
    "basefoldername = str(date.today())\n",
    "i = 0\n",
    "while True:\n",
    "    foldername = f'{basefoldername}-{i}'\n",
    "    full_foldername = path.join(outputdir, foldername)\n",
    "\n",
    "    if not path.exists(full_foldername):\n",
    "      mkdir(full_foldername)\n",
    "      break\n",
    "\n",
    "    if not any(listdir(full_foldername)): break\n",
    "    i = i + 1\n",
    "\n",
    "expname = ''\n",
    "def log(message):\n",
    "    print(f'[batch:{expname}] {message}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generation Methods\n",
    "\n",
    "from functools import reduce\n",
    "import re\n",
    "\n",
    "# Prepare a command string to send to ornette via CLI\n",
    "def escape_command(commands):\n",
    "  commands = re.split('\\n|;', commands)\n",
    "  commands = [line.split(' ') for line in commands]\n",
    "  commands = ['\\ '.join(line) for line in commands]\n",
    "  commands = '\\;'.join(commands)\n",
    "  return commands\n",
    "\n",
    "def get_filename(modelname, checkpointname, primer, index, bars_input, bars_output):\n",
    "  return f'{foldername}/{modelname}-{checkpointname}-{index}-{bars_input}-{bars_output}-{primer}'\n",
    "\n",
    "# WIP: another approach, via CLI args\n",
    "def get_generation_command(the_modelname, the_checkpointname, output_tracks, datapath, primer, bars_input, bars_output, count):\n",
    "  \n",
    "  # Main generation loop\n",
    "  exec_cmd = ';\\n'.join([f'generate {bars_output} bars'\n",
    "      for i in range(1000) # FIXME: This can be better calculated\n",
    "      if i * bars_output < sample_length])\n",
    "\n",
    "  # Reset, load the primer again, generate, save\n",
    "  exec_cmd = ['\\n;'.join(\n",
    "      [ 'reset;'\n",
    "      , f'load {datapath}/{primer} {bars_input}'\n",
    "      , exec_cmd\n",
    "      , f'save {get_filename(the_modelname, the_checkpointname, primer, index, bars_input, bars_output)}'\n",
    "      , 'end'\n",
    "      ]\n",
    "    )\n",
    "    for index\n",
    "    in range(count)]\n",
    "  \n",
    "  # WIP: Input Length is always 16 (why??)\n",
    "  # Before running generation: set variables\n",
    "  exec_vars = [ 'set debug_output True;'\n",
    "    , 'set batch_mode True;'\n",
    "    , 'set playback False;'\n",
    "    , 'set trigger_generate 1;'\n",
    "    , 'set batch_unit measures;'\n",
    "    , 'set debug_output False;'\n",
    "    , f'set input_length {bars_input};'\n",
    "    , f'set input_unit bars;'\n",
    "    , f'set output_length {bars_output};'\n",
    "    , f'set output_unit bars;'\n",
    "  ]\n",
    "\n",
    "  if output_tracks: exec_vars.append('set output_tracks ' + output_tracks + ';')\n",
    "\n",
    "  # Combine Lines\n",
    "  exec_cmd = '\\n'.join(exec_vars + exec_cmd)\n",
    "\n",
    "  # Escape string to pass it via CLI\n",
    "  exec_cmd = escape_command(exec_cmd)\n",
    "  return exec_cmd\n",
    "\n",
    "\n",
    "logfile = None\n",
    "def generate_samples(the_modelname, the_checkpointname, output_tracks, datapath, primer, bars_input, bars_output, count):\n",
    "\n",
    "    # Set logging prefix\n",
    "    modelname = the_modelname\n",
    "    checkpointname = the_checkpointname\n",
    "    log(f'Generating ({modelname}:{checkpointname}) samples with {primer}')\n",
    "\n",
    "    # Get Ornette CLI command\n",
    "    if datapath.startswith('.'): datapath = datapath[1:]\n",
    "    cmd = get_generation_command(the_modelname, the_checkpointname, output_tracks, datapath, primer, bars_input, bars_output, count)\n",
    "    # print(cmd.split(';')[-1])\n",
    "    # print('\\n'.join(cmd.split(';')))\n",
    "\n",
    "    # Process filenames\n",
    "    filenames = [get_filename(the_modelname, the_checkpointname, primer, index, bars_input, bars_output) for index in range(count)]\n",
    "    log(filenames)\n",
    "\n",
    "\n",
    "    # Run (and time) the generation batch\n",
    "    env = environ.copy()\n",
    "    logfile = open(path.join(outputdir, f'{the_modelname}.log'), 'w')\n",
    "\n",
    "    start_time = monotonic()\n",
    "    server = subprocess.run(\n",
    "        ['python'\n",
    "        , '.'\n",
    "        , '--modelname'\n",
    "        , modelname\n",
    "        , '--checkpoint'\n",
    "        , checkpoint\n",
    "        , '--exec'\n",
    "        , cmd\n",
    "        ]\n",
    "      , env=env\n",
    "      , stdout=logfile\n",
    "      , stderr=logfile\n",
    "      # , stdout=subprocess.PIPE\n",
    "      )\n",
    "    # server.communicate()\n",
    "    if server.stdout: print(server.stdout.strip().decode('utf-8'))\n",
    "    if server.stderr: print(server.stderr.strip().decode('utf-8'))\n",
    "    end_time = monotonic()\n",
    "    \n",
    "    # Calculate total generation time\n",
    "    gentime = end_time - start_time\n",
    "    return [(filenames, gentime)]\n",
    "\n",
    "def run_generation(model, checkpoint, datapath, primers, output_tracks):\n",
    "  \n",
    "  # filenames, gentime = generate_samples(model, checkpoint, datapath, primer, bars_input, bars_output, iterations)\n",
    "  return [\n",
    "    [ model\n",
    "    , checkpoint\n",
    "    , dataset\n",
    "    , primer\n",
    "    , iterations # TODO: pass iterations to generate samples / use iterations here\n",
    "    # , *generate_samples(model, checkpoint, datapath, primer, bars_input, bars_output, iterations)\n",
    "    , filename\n",
    "    , gentime\n",
    "    , bars_input\n",
    "    , bars_output\n",
    "    ]\n",
    "    for bars_input in range(min_input_bars,max_input_bars + 1)\n",
    "    for bars_output in range(min_output_bars,max_output_bars + 1)\n",
    "    for primer in primers\n",
    "    for (filenames, gentime) in generate_samples(model, checkpoint, output_tracks, datapath, primer, bars_input, bars_output, iterations)\n",
    "    for filename in filenames\n",
    "  ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ", 14.688822159077972, 1, 1], ['performance_rnn', 'pitch_conditioned_performance_with_dynamics', 'piano-e-comp', 'ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_12_R1_2013_wav--4.midi', 1, '2021-08-05-1/performance_rnn-pitch_conditioned_performance_with_dynamics-0-1-1-ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_12_R1_2013_wav--4.midi', 12.368907444062643, 1, 1], ['performance_rnn', 'pitch_conditioned_performance_with_dynamics', 'piano-e-comp', 'MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_19_R1_2015_wav--4.midi', 1, '2021-08-05-1/performance_rnn-pitch_conditioned_performance_with_dynamics-0-1-2-MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_19_R1_2015_wav--4.midi', 11.411634993040934, 1, 2], ['performance_rnn', 'pitch_conditioned_performance_with_dynamics', 'piano-e-comp', 'MIDI-Unprocessed_051_PIANO051_MID--AUDIO-split_07-06-17_Piano-e_3-02_wav--3.midi', 1, '2021-08-05-1/performance_rnn-pitch_conditioned_performance_with_dynamics-0-1-2-MIDI-Unprocessed_051_PIANO051_MID--AUDIO-split_07-06-17_Piano-e_3-02_wav--3.midi', 7.553350188070908, 1, 2], ['performance_rnn', 'pitch_conditioned_performance_with_dynamics', 'piano-e-comp', 'MIDI-Unprocessed_XP_20_R2_2004_01_ORIG_MID--AUDIO_20_R1_2004_01_Track01_wav.midi', 1, '2021-08-05-1/performance_rnn-pitch_conditioned_performance_with_dynamics-0-1-2-MIDI-Unprocessed_XP_20_R2_2004_01_ORIG_MID--AUDIO_20_R1_2004_01_Track01_wav.midi', 12.291130486992188, 1, 2], ['performance_rnn', 'pitch_conditioned_performance_with_dynamics', 'piano-e-comp', 'MIDI-Unprocessed_24_R1_2006_01-05_ORIG_MID--AUDIO_24_R1_2006_05_Track05_wav.midi', 1, '2021-08-05-1/performance_rnn-pitch_conditioned_performance_with_dynamics-0-1-2-MIDI-Unprocessed_24_R1_2006_01-05_ORIG_MID--AUDIO_24_R1_2006_05_Track05_wav.midi', 10.379460632102564, 1, 2], ['performance_rnn', 'pitch_conditioned_performance_with_dynamics', 'piano-e-comp', 'ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_12_R1_2013_wav--4.midi', 1, '2021-08-05-1/performance_rnn-pitch_conditioned_performance_with_dynamics-0-1-2-ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_12_R1_2013_wav--4.midi', 10.725966742029414, 1, 2], ['performance_rnn', 'pitch_conditioned_performance_with_dynamics', 'piano-e-comp', 'MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_19_R1_2015_wav--4.midi', 1, '2021-08-05-1/performance_rnn-pitch_conditioned_performance_with_dynamics-0-2-1-MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_19_R1_2015_wav--4.midi', 13.855874556931667, 2, 1], ['performance_rnn', 'pitch_conditioned_performance_with_dynamics', 'piano-e-comp', 'MIDI-Unprocessed_051_PIANO051_MID--AUDIO-split_07-06-17_Piano-e_3-02_wav--3.midi', 1, '2021-08-05-1/performance_rnn-pitch_conditioned_performance_with_dynamics-0-2-1-MIDI-Unprocessed_051_PIANO051_MID--AUDIO-split_07-06-17_Piano-e_3-02_wav--3.midi', 11.943472185987048, 2, 1], ['performance_rnn', 'pitch_conditioned_performance_with_dynamics', 'piano-e-comp', 'MIDI-Unprocessed_XP_20_R2_2004_01_ORIG_MID--AUDIO_20_R1_2004_01_Track01_wav.midi', 1, '2021-08-05-1/performance_rnn-pitch_conditioned_performance_with_dynamics-0-2-1-MIDI-Unprocessed_XP_20_R2_2004_01_ORIG_MID--AUDIO_20_R1_2004_01_Track01_wav.midi', 10.06174357898999, 2, 1], ['performance_rnn', 'pitch_conditioned_performance_with_dynamics', 'piano-e-comp', 'MIDI-Unprocessed_24_R1_2006_01-05_ORIG_MID--AUDIO_24_R1_2006_05_Track05_wav.midi', 1, '2021-08-05-1/performance_rnn-pitch_conditioned_performance_with_dynamics-0-2-1-MIDI-Unprocessed_24_R1_2006_01-05_ORIG_MID--AUDIO_24_R1_2006_05_Track05_wav.midi', 6.543509560986422, 2, 1], ['performance_rnn', 'pitch_conditioned_performance_with_dynamics', 'piano-e-comp', 'ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_12_R1_2013_wav--4.midi', 1, '2021-08-05-1/performance_rnn-pitch_conditioned_performance_with_dynamics-0-2-1-ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_12_R1_2013_wav--4.midi', 16.74150208104402, 2, 1], ['performance_rnn', 'pitch_conditioned_performance_with_dynamics', 'piano-e-comp', 'MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_19_R1_2015_wav--4.midi', 1, '2021-08-05-1/performance_rnn-pitch_conditioned_performance_with_dynamics-0-2-2-MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_19_R1_2015_wav--4.midi', 23.059772670967504, 2, 2], ['performance_rnn', 'pitch_conditioned_performance_with_dynamics', 'piano-e-comp', 'MIDI-Unprocessed_051_PIANO051_MID--AUDIO-split_07-06-17_Piano-e_3-02_wav--3.midi', 1, '2021-08-05-1/performance_rnn-pitch_conditioned_performance_with_dynamics-0-2-2-MIDI-Unprocessed_051_PIANO051_MID--AUDIO-split_07-06-17_Piano-e_3-02_wav--3.midi', 10.725001954007894, 2, 2], ['performance_rnn', 'pitch_conditioned_performance_with_dynamics', 'piano-e-comp', 'MIDI-Unprocessed_XP_20_R2_2004_01_ORIG_MID--AUDIO_20_R1_2004_01_Track01_wav.midi', 1, '2021-08-05-1/performance_rnn-pitch_conditioned_performance_with_dynamics-0-2-2-MIDI-Unprocessed_XP_20_R2_2004_01_ORIG_MID--AUDIO_20_R1_2004_01_Track01_wav.midi', 12.206815325072967, 2, 2], ['performance_rnn', 'pitch_conditioned_performance_with_dynamics', 'piano-e-comp', 'MIDI-Unprocessed_24_R1_2006_01-05_ORIG_MID--AUDIO_24_R1_2006_05_Track05_wav.midi', 1, '2021-08-05-1/performance_rnn-pitch_conditioned_performance_with_dynamics-0-2-2-MIDI-Unprocessed_24_R1_2006_01-05_ORIG_MID--AUDIO_24_R1_2006_05_Track05_wav.midi', 13.65533671702724, 2, 2], ['performance_rnn', 'pitch_conditioned_performance_with_dynamics', 'piano-e-comp', 'ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_12_R1_2013_wav--4.midi', 1, '2021-08-05-1/performance_rnn-pitch_conditioned_performance_with_dynamics-0-2-2-ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_12_R1_2013_wav--4.midi', 13.996320239966735, 2, 2], ['performance_rnn', 'multiconditioned_performance_with_dynamics', 'piano-e-comp', 'MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_19_R1_2015_wav--4.midi', 1, '2021-08-05-1/performance_rnn-multiconditioned_performance_with_dynamics-0-1-1-MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_19_R1_2015_wav--4.midi', 10.094489934039302, 1, 1], ['performance_rnn', 'multiconditioned_performance_with_dynamics', 'piano-e-comp', 'MIDI-Unprocessed_051_PIANO051_MID--AUDIO-split_07-06-17_Piano-e_3-02_wav--3.midi', 1, '2021-08-05-1/performance_rnn-multiconditioned_performance_with_dynamics-0-1-1-MIDI-Unprocessed_051_PIANO051_MID--AUDIO-split_07-06-17_Piano-e_3-02_wav--3.midi', 9.570787798962556, 1, 1], ['performance_rnn', 'multiconditioned_performance_with_dynamics', 'piano-e-comp', 'MIDI-Unprocessed_XP_20_R2_2004_01_ORIG_MID--AUDIO_20_R1_2004_01_Track01_wav.midi', 1, '2021-08-05-1/performance_rnn-multiconditioned_performance_with_dynamics-0-1-1-MIDI-Unprocessed_XP_20_R2_2004_01_ORIG_MID--AUDIO_20_R1_2004_01_Track01_wav.midi', 10.6466134339571, 1, 1], ['performance_rnn', 'multiconditioned_performance_with_dynamics', 'piano-e-comp', 'MIDI-Unprocessed_24_R1_2006_01-05_ORIG_MID--AUDIO_24_R1_2006_05_Track05_wav.midi', 1, '2021-08-05-1/performance_rnn-multiconditioned_performance_with_dynamics-0-1-1-MIDI-Unprocessed_24_R1_2006_01-05_ORIG_MID--AUDIO_24_R1_2006_05_Track05_wav.midi', 9.826339513994753, 1, 1], ['performance_rnn', 'multiconditioned_performance_with_dynamics', 'piano-e-comp', 'ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_12_R1_2013_wav--4.midi', 1, '2021-08-05-1/performance_rnn-multiconditioned_performance_with_dynamics-0-1-1-ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_12_R1_2013_wav--4.midi', 10.674578464007936, 1, 1], ['performance_rnn', 'multiconditioned_performance_with_dynamics', 'piano-e-comp', 'MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_19_R1_2015_wav--4.midi', 1, '2021-08-05-1/performance_rnn-multiconditioned_performance_with_dynamics-0-1-2-MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_19_R1_2015_wav--4.midi', 7.903851486044005, 1, 2], ['performance_rnn', 'multiconditioned_performance_with_dynamics', 'piano-e-comp', 'MIDI-Unprocessed_051_PIANO051_MID--AUDIO-split_07-06-17_Piano-e_3-02_wav--3.midi', 1, '2021-08-05-1/performance_rnn-multiconditioned_performance_with_dynamics-0-1-2-MIDI-Unprocessed_051_PIANO051_MID--AUDIO-split_07-06-17_Piano-e_3-02_wav--3.midi', 8.252129205036908, 1, 2], ['performance_rnn', 'multiconditioned_performance_with_dynamics', 'piano-e-comp', 'MIDI-Unprocessed_XP_20_R2_2004_01_ORIG_MID--AUDIO_20_R1_2004_01_Track01_wav.midi', 1, '2021-08-05-1/performance_rnn-multiconditioned_performance_with_dynamics-0-1-2-MIDI-Unprocessed_XP_20_R2_2004_01_ORIG_MID--AUDIO_20_R1_2004_01_Track01_wav.midi', 10.025798848015256, 1, 2], ['performance_rnn', 'multiconditioned_performance_with_dynamics', 'piano-e-comp', 'MIDI-Unprocessed_24_R1_2006_01-05_ORIG_MID--AUDIO_24_R1_2006_05_Track05_wav.midi', 1, '2021-08-05-1/performance_rnn-multiconditioned_performance_with_dynamics-0-1-2-MIDI-Unprocessed_24_R1_2006_01-05_ORIG_MID--AUDIO_24_R1_2006_05_Track05_wav.midi', 10.289980088011362, 1, 2], ['performance_rnn', 'multiconditioned_performance_with_dynamics', 'piano-e-comp', 'ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_12_R1_2013_wav--4.midi', 1, '2021-08-05-1/performance_rnn-multiconditioned_performance_with_dynamics-0-1-2-ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_12_R1_2013_wav--4.midi', 11.091891591087915, 1, 2], ['performance_rnn', 'multiconditioned_performance_with_dynamics', 'piano-e-comp', 'MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_19_R1_2015_wav--4.midi', 1, '2021-08-05-1/performance_rnn-multiconditioned_performance_with_dynamics-0-2-1-MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_19_R1_2015_wav--4.midi', 13.967915246030316, 2, 1], ['performance_rnn', 'multiconditioned_performance_with_dynamics', 'piano-e-comp', 'MIDI-Unprocessed_051_PIANO051_MID--AUDIO-split_07-06-17_Piano-e_3-02_wav--3.midi', 1, '2021-08-05-1/performance_rnn-multiconditioned_performance_with_dynamics-0-2-1-MIDI-Unprocessed_051_PIANO051_MID--AUDIO-split_07-06-17_Piano-e_3-02_wav--3.midi', 11.005819328012876, 2, 1], ['performance_rnn', 'multiconditioned_performance_with_dynamics', 'piano-e-comp', 'MIDI-Unprocessed_XP_20_R2_2004_01_ORIG_MID--AUDIO_20_R1_2004_01_Track01_wav.midi', 1, '2021-08-05-1/performance_rnn-multiconditioned_performance_with_dynamics-0-2-1-MIDI-Unprocessed_XP_20_R2_2004_01_ORIG_MID--AUDIO_20_R1_2004_01_Track01_wav.midi', 11.899346639984287, 2, 1], ['performance_rnn', 'multiconditioned_performance_with_dynamics', 'piano-e-comp', 'MIDI-Unprocessed_24_R1_2006_01-05_ORIG_MID--AUDIO_24_R1_2006_05_Track05_wav.midi', 1, '2021-08-05-1/performance_rnn-multiconditioned_performance_with_dynamics-0-2-1-MIDI-Unprocessed_24_R1_2006_01-05_ORIG_MID--AUDIO_24_R1_2006_05_Track05_wav.midi', 13.885459861019626, 2, 1], ['performance_rnn', 'multiconditioned_performance_with_dynamics', 'piano-e-comp', 'ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_12_R1_2013_wav--4.midi', 1, '2021-08-05-1/performance_rnn-multiconditioned_performance_with_dynamics-0-2-1-ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_12_R1_2013_wav--4.midi', 9.178691099048592, 2, 1], ['performance_rnn', 'multiconditioned_performance_with_dynamics', 'piano-e-comp', 'MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_19_R1_2015_wav--4.midi', 1, '2021-08-05-1/performance_rnn-multiconditioned_performance_with_dynamics-0-2-2-MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_19_R1_2015_wav--4.midi', 8.706888407003134, 2, 2], ['performance_rnn', 'multiconditioned_performance_with_dynamics', 'piano-e-comp', 'MIDI-Unprocessed_051_PIANO051_MID--AUDIO-split_07-06-17_Piano-e_3-02_wav--3.midi', 1, '2021-08-05-1/performance_rnn-multiconditioned_performance_with_dynamics-0-2-2-MIDI-Unprocessed_051_PIANO051_MID--AUDIO-split_07-06-17_Piano-e_3-02_wav--3.midi', 10.774488887982443, 2, 2], ['performance_rnn', 'multiconditioned_performance_with_dynamics', 'piano-e-comp', 'MIDI-Unprocessed_XP_20_R2_2004_01_ORIG_MID--AUDIO_20_R1_2004_01_Track01_wav.midi', 1, '2021-08-05-1/performance_rnn-multiconditioned_performance_with_dynamics-0-2-2-MIDI-Unprocessed_XP_20_R2_2004_01_ORIG_MID--AUDIO_20_R1_2004_01_Track01_wav.midi', 10.313975529978052, 2, 2], ['performance_rnn', 'multiconditioned_performance_with_dynamics', 'piano-e-comp', 'MIDI-Unprocessed_24_R1_2006_01-05_ORIG_MID--AUDIO_24_R1_2006_05_Track05_wav.midi', 1, '2021-08-05-1/performance_rnn-multiconditioned_performance_with_dynamics-0-2-2-MIDI-Unprocessed_24_R1_2006_01-05_ORIG_MID--AUDIO_24_R1_2006_05_Track05_wav.midi', 14.78920962603297, 2, 2], ['performance_rnn', 'multiconditioned_performance_with_dynamics', 'piano-e-comp', 'ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_12_R1_2013_wav--4.midi', 1, '2021-08-05-1/performance_rnn-multiconditioned_performance_with_dynamics-0-2-2-ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_12_R1_2013_wav--4.midi', 9.523681596037932, 2, 2], ['performance_rnn', 'performance_with_dynamics_and_modulo_encoding', 'piano-e-comp', 'MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_19_R1_2015_wav--4.midi', 1, '2021-08-05-1/performance_rnn-performance_with_dynamics_and_modulo_encoding-0-1-1-MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_19_R1_2015_wav--4.midi', 8.018012649030425, 1, 1], ['performance_rnn', 'performance_with_dynamics_and_modulo_encoding', 'piano-e-comp', 'MIDI-Unprocessed_051_PIANO051_MID--AUDIO-split_07-06-17_Piano-e_3-02_wav--3.midi', 1, '2021-08-05-1/performance_rnn-performance_with_dynamics_and_modulo_encoding-0-1-1-MIDI-Unprocessed_051_PIANO051_MID--AUDIO-split_07-06-17_Piano-e_3-02_wav--3.midi', 7.717282282072119, 1, 1], ['performance_rnn', 'performance_with_dynamics_and_modulo_encoding', 'piano-e-comp', 'MIDI-Unprocessed_XP_20_R2_2004_01_ORIG_MID--AUDIO_20_R1_2004_01_Track01_wav.midi', 1, '2021-08-05-1/performance_rnn-performance_with_dynamics_and_modulo_encoding-0-1-1-MIDI-Unprocessed_XP_20_R2_2004_01_ORIG_MID--AUDIO_20_R1_2004_01_Track01_wav.midi', 7.682273072074167, 1, 1], ['performance_rnn', 'performance_with_dynamics_and_modulo_encoding', 'piano-e-comp', 'MIDI-Unprocessed_24_R1_2006_01-05_ORIG_MID--AUDIO_24_R1_2006_05_Track05_wav.midi', 1, '2021-08-05-1/performance_rnn-performance_with_dynamics_and_modulo_encoding-0-1-1-MIDI-Unprocessed_24_R1_2006_01-05_ORIG_MID--AUDIO_24_R1_2006_05_Track05_wav.midi', 7.006720675039105, 1, 1], ['performance_rnn', 'performance_with_dynamics_and_modulo_encoding', 'piano-e-comp', 'ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_12_R1_2013_wav--4.midi', 1, '2021-08-05-1/performance_rnn-performance_with_dynamics_and_modulo_encoding-0-1-1-ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_12_R1_2013_wav--4.midi', 8.059202073025517, 1, 1], ['performance_rnn', 'performance_with_dynamics_and_modulo_encoding', 'piano-e-comp', 'MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_19_R1_2015_wav--4.midi', 1, '2021-08-05-1/performance_rnn-performance_with_dynamics_and_modulo_encoding-0-1-2-MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_19_R1_2015_wav--4.midi', 7.962361374986358, 1, 2], ['performance_rnn', 'performance_with_dynamics_and_modulo_encoding', 'piano-e-comp', 'MIDI-Unprocessed_051_PIANO051_MID--AUDIO-split_07-06-17_Piano-e_3-02_wav--3.midi', 1, '2021-08-05-1/performance_rnn-performance_with_dynamics_and_modulo_encoding-0-1-2-MIDI-Unprocessed_051_PIANO051_MID--AUDIO-split_07-06-17_Piano-e_3-02_wav--3.midi', 7.272953390027396, 1, 2], ['performance_rnn', 'performance_with_dynamics_and_modulo_encoding', 'piano-e-comp', 'MIDI-Unprocessed_XP_20_R2_2004_01_ORIG_MID--AUDIO_20_R1_2004_01_Track01_wav.midi', 1, '2021-08-05-1/performance_rnn-performance_with_dynamics_and_modulo_encoding-0-1-2-MIDI-Unprocessed_XP_20_R2_2004_01_ORIG_MID--AUDIO_20_R1_2004_01_Track01_wav.midi', 9.401111642015167, 1, 2], ['performance_rnn', 'performance_with_dynamics_and_modulo_encoding', 'piano-e-comp', 'MIDI-Unprocessed_24_R1_2006_01-05_ORIG_MID--AUDIO_24_R1_2006_05_Track05_wav.midi', 1, '2021-08-05-1/performance_rnn-performance_with_dynamics_and_modulo_encoding-0-1-2-MIDI-Unprocessed_24_R1_2006_01-05_ORIG_MID--AUDIO_24_R1_2006_05_Track05_wav.midi', 8.733589914045297, 1, 2], ['performance_rnn', 'performance_with_dynamics_and_modulo_encoding', 'piano-e-comp', 'ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_12_R1_2013_wav--4.midi', 1, '2021-08-05-1/performance_rnn-performance_with_dynamics_and_modulo_encoding-0-1-2-ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_12_R1_2013_wav--4.midi', 7.395351574057713, 1, 2], ['performance_rnn', 'performance_with_dynamics_and_modulo_encoding', 'piano-e-comp', 'MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_19_R1_2015_wav--4.midi', 1, '2021-08-05-1/performance_rnn-performance_with_dynamics_and_modulo_encoding-0-2-1-MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_19_R1_2015_wav--4.midi', 19.19206737994682, 2, 1], ['performance_rnn', 'performance_with_dynamics_and_modulo_encoding', 'piano-e-comp', 'MIDI-Unprocessed_051_PIANO051_MID--AUDIO-split_07-06-17_Piano-e_3-02_wav--3.midi', 1, '2021-08-05-1/performance_rnn-performance_with_dynamics_and_modulo_encoding-0-2-1-MIDI-Unprocessed_051_PIANO051_MID--AUDIO-split_07-06-17_Piano-e_3-02_wav--3.midi', 10.792089522932656, 2, 1], ['performance_rnn', 'performance_with_dynamics_and_modulo_encoding', 'piano-e-comp', 'MIDI-Unprocessed_XP_20_R2_2004_01_ORIG_MID--AUDIO_20_R1_2004_01_Track01_wav.midi', 1, '2021-08-05-1/performance_rnn-performance_with_dynamics_and_modulo_encoding-0-2-1-MIDI-Unprocessed_XP_20_R2_2004_01_ORIG_MID--AUDIO_20_R1_2004_01_Track01_wav.midi', 8.745154933072627, 2, 1], ['performance_rnn', 'performance_with_dynamics_and_modulo_encoding', 'piano-e-comp', 'MIDI-Unprocessed_24_R1_2006_01-05_ORIG_MID--AUDIO_24_R1_2006_05_Track05_wav.midi', 1, '2021-08-05-1/performance_rnn-performance_with_dynamics_and_modulo_encoding-0-2-1-MIDI-Unprocessed_24_R1_2006_01-05_ORIG_MID--AUDIO_24_R1_2006_05_Track05_wav.midi', 9.637522678938694, 2, 1], ['performance_rnn', 'performance_with_dynamics_and_modulo_encoding', 'piano-e-comp', 'ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_12_R1_2013_wav--4.midi', 1, '2021-08-05-1/performance_rnn-performance_with_dynamics_and_modulo_encoding-0-2-1-ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_12_R1_2013_wav--4.midi', 8.149344654986635, 2, 1], ['performance_rnn', 'performance_with_dynamics_and_modulo_encoding', 'piano-e-comp', 'MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_19_R1_2015_wav--4.midi', 1, '2021-08-05-1/performance_rnn-performance_with_dynamics_and_modulo_encoding-0-2-2-MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_19_R1_2015_wav--4.midi', 11.292879636050202, 2, 2], ['performance_rnn', 'performance_with_dynamics_and_modulo_encoding', 'piano-e-comp', 'MIDI-Unprocessed_051_PIANO051_MID--AUDIO-split_07-06-17_Piano-e_3-02_wav--3.midi', 1, '2021-08-05-1/performance_rnn-performance_with_dynamics_and_modulo_encoding-0-2-2-MIDI-Unprocessed_051_PIANO051_MID--AUDIO-split_07-06-17_Piano-e_3-02_wav--3.midi', 6.806609016028233, 2, 2], ['performance_rnn', 'performance_with_dynamics_and_modulo_encoding', 'piano-e-comp', 'MIDI-Unprocessed_XP_20_R2_2004_01_ORIG_MID--AUDIO_20_R1_2004_01_Track01_wav.midi', 1, '2021-08-05-1/performance_rnn-performance_with_dynamics_and_modulo_encoding-0-2-2-MIDI-Unprocessed_XP_20_R2_2004_01_ORIG_MID--AUDIO_20_R1_2004_01_Track01_wav.midi', 8.588452739990316, 2, 2], ['performance_rnn', 'performance_with_dynamics_and_modulo_encoding', 'piano-e-comp', 'MIDI-Unprocessed_24_R1_2006_01-05_ORIG_MID--AUDIO_24_R1_2006_05_Track05_wav.midi', 1, '2021-08-05-1/performance_rnn-performance_with_dynamics_and_modulo_encoding-0-2-2-MIDI-Unprocessed_24_R1_2006_01-05_ORIG_MID--AUDIO_24_R1_2006_05_Track05_wav.midi', 8.312064182013273, 2, 2], ['performance_rnn', 'performance_with_dynamics_and_modulo_encoding', 'piano-e-comp', 'ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_12_R1_2013_wav--4.midi', 1, '2021-08-05-1/performance_rnn-performance_with_dynamics_and_modulo_encoding-0-2-2-ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_12_R1_2013_wav--4.midi', 8.44436747697182, 2, 2]]\n",
      "       iteration        time      in_len     out_len\n",
      "count      260.0  260.000000  260.000000  260.000000\n",
      "mean         1.0    8.483020    1.500000    1.500000\n",
      "std          0.0    4.599983    0.500964    0.500964\n",
      "min          1.0    0.718924    1.000000    1.000000\n",
      "25%          1.0    7.270477    1.000000    1.000000\n",
      "50%          1.0    8.720434    1.500000    1.500000\n",
      "75%          1.0   10.797727    2.000000    2.000000\n",
      "max          1.0   23.059773    2.000000    2.000000\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Generation Phase\n",
    "\n",
    "import pickle\n",
    "\n",
    "max_primers = None\n",
    "max_primers = 5\n",
    "\n",
    "try:\n",
    "    log(f'Starting experiment suite: {outputdir}/{foldername}')\n",
    "\n",
    "    # Set logging prefix\n",
    "\n",
    "    output = []\n",
    "    for dataset, models in evaluation_sets:\n",
    "        if dataset is None: continue\n",
    "        datapath = path.join(datasetdir, dataset)\n",
    "        primerdir = datapath\n",
    "        if not path.exists(datapath):\n",
    "            print(f'Directory not found: {datapath}, skipping')\n",
    "            continue\n",
    "\n",
    "        primers = listdir(datapath)\n",
    "        if max_primers: primers = primers[:max_primers]\n",
    "\n",
    "        for (model, checkpoint, output_tracks) in models:\n",
    "            expname = model\n",
    "            # start_model(model, checkpoint)\n",
    "\n",
    "            e = run_generation(model, checkpoint, datapath, primers, output_tracks)\n",
    "\n",
    "            output += e\n",
    "    print(output)\n",
    "    # Save temp file\n",
    "    # with open('output/output.tmp', 'wb') as f:\n",
    "    #   pickle.dump(output, f)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(output, columns=cols_gen)\n",
    "    print(df.describe())\n",
    "    df.to_pickle(path.join(outputdir, 'df_gen'))\n",
    "    \n",
    "\n",
    "except KeyboardInterrupt:\n",
    "  print(\"Terminating...\")\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DataFrame checked!\n"
     ]
    }
   ],
   "source": [
    "# Filter Data\n",
    "import pandas as pd\n",
    "df_gen = pd.read_pickle('output/df_gen')\n",
    "df_gen.to_pickle(path.join(outputdir, 'df_gen_bk'))\n",
    "\n",
    "# Get Models\n",
    "def get_models(df_):\n",
    "    df_['uniquename'] = df_['model'] + ':' + df_['checkpoint']\n",
    "    uniques = [x for x in df_['uniquename'].unique()]\n",
    "    return uniques\n",
    "\n",
    "# Only where an output file exists\n",
    "df_success = df_gen[df_gen.apply(lambda x: os.path.exists(f'output/{x[\"out_file\"]}.mid'),axis=1)]\n",
    "\n",
    "# print(newdf)\n",
    "err = [name for name\n",
    "  in get_models(df_gen)\n",
    "  if name not in get_models(df_success)]\n",
    "\n",
    "if any(err):\n",
    "    df_success.to_pickle(path.join(outputdir, 'df_gen'))\n",
    "    print(f'The following models had problems at generation time and will not be analysed: {\", \".join(err)}')\n",
    "else:\n",
    "  print(\"DataFrame checked!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "melody_rnn:attention_rnn:   0%|          | 0/48 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ghales/git/tg-server/output/metrics'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c142317a137b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;31m# Read Extracted features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetricsfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmetricsfile_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0mrow_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetricsfile_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/ghales/git/tg-server/output/metrics'"
     ]
    }
   ],
   "source": [
    "# Analysis Stage\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "outputdir = os.path.abspath(os.path.join(os.curdir, 'output'))\n",
    "df_gen = pd.read_pickle(os.path.join(outputdir, 'df_gen'))\n",
    "metricsfile = os.path.join(outputdir, 'metrics')\n",
    "\n",
    "output_samples_dir  = os.path.join(outputdir, 'samples')\n",
    "output_dataset_dir  = os.path.join(outputdir, 'dataset')\n",
    "\n",
    "# Define External Commands\n",
    "extraction_scriptdir = os.path.abspath(os.path.join(os.path.pardir, 'mgeval'))\n",
    "extraction_script = os.path.join(extraction_scriptdir, 'start.sh') \n",
    "cmd_extraction = [ 'bash', extraction_script, output_samples_dir, output_dataset_dir, metricsfile, str(sample_length) ]\n",
    "\n",
    "preprocess_scriptdir = os.path.abspath(os.path.join(os.path.pardir, 'miditools'))\n",
    "preprocess_script = os.path.join(preprocess_scriptdir, 'midisox_py')\n",
    "cmd_preprocess = lambda _in, _out: [ 'python', preprocess_script, '-m', os.path.abspath(_in), os.path.abspath(_out) ]\n",
    "\n",
    "# Prepare output log file\n",
    "logfile = open(path.join(outputdir, f'analysis.log'), 'w')\n",
    "\n",
    "# Prepare Metrics DF\n",
    "df_metrics = df_gen\n",
    "\n",
    "# FIXME: Missing 'checkpoint' column\n",
    "\n",
    "# Prepare Output Data Fields\n",
    "metriccolumns = ['model', 'checkpoint', 'in_len', 'out_len', 'iteration']\n",
    "metrics_initialized = False\n",
    "out = []\n",
    "\n",
    "\n",
    "datadirs = [ output_samples_dir, output_dataset_dir ]\n",
    "\n",
    "# Iterate combinations of input/output windows\n",
    "grouping = df_metrics.groupby(['model', 'checkpoint', 'in_len', 'out_len', 'dataset', 'iteration'])\n",
    "t = tqdm(grouping.out_file)\n",
    "for (model, checkpoint, inn, outn, dataset, iteration), outfiles in t:\n",
    "    # if model == 'melody_rnn': continue\n",
    "    expname = model\n",
    "    t.set_description(f'{model}:{checkpoint}')\n",
    "\n",
    "    for _dir in datadirs:\n",
    "        # Check that directory exists\n",
    "        if not os.path.exists(_dir):\n",
    "            os.mkdir(_dir)\n",
    "\n",
    "        # Clean output directory\n",
    "        for file in glob.glob(os.path.join(_dir,'*')):\n",
    "            # log(f'removing: {file}')\n",
    "            if not os.path.exists(file): continue\n",
    "            if os.path.islink(file): os.unlink(file)\n",
    "            else: os.remove(file)\n",
    "\n",
    "    # Remove previous metrics file if any (for sanity)\n",
    "    if os.path.exists(metricsfile):\n",
    "        os.remove(metricsfile)\n",
    "\n",
    "    # Prepare Baseline Dataset Samples\n",
    "    dataset_samples = glob.glob(os.path.join(os.path.curdir, 'dataset', dataset, '*'))\n",
    "    \n",
    "    # FIXME\n",
    "    dataset_samples = dataset_samples[:len(outfiles.unique())]\n",
    "    for index, filename in enumerate(dataset_samples):\n",
    "        out_filename = os.path.join(outputdir, 'dataset', f'sample-{index}.mid')\n",
    "        subprocess.call(cmd_preprocess(filename, out_filename), stdout=logfile, stderr=logfile, cwd=preprocess_scriptdir)\n",
    "    \n",
    "    # Prepare Output Samples \n",
    "    for o, outfile in enumerate(outfiles.unique()):\n",
    "\n",
    "        # Create link to file\n",
    "        in_filename = os.path.abspath(os.path.join(\"output\", f\"{outfile}.mid\"))\n",
    "        out_filename = os.path.abspath(os.path.join(output_samples_dir, f'sample-{o}.mid'))\n",
    "        # log(f'creating: {file}')\n",
    "        # log('processing: ' + ' '.join(cmd_preprocess(in_filename, out_filename)))\n",
    "        # log(f'({inn} | {outn} bars) processing file: {in_filename} -> {out_filename}')\n",
    "        subprocess.call(cmd_preprocess(in_filename, out_filename), stdout=logfile, stderr=logfile, cwd=preprocess_scriptdir)\n",
    "\n",
    "    # Extract Features\n",
    "    # print(f'Extracting metrics from {model}:{checkpoint}')\n",
    "    subprocess.call(cmd_extraction, stdout=logfile, stderr=logfile, cwd=extraction_scriptdir)\n",
    "\n",
    "    # Read Extracted features\n",
    "    with open(metricsfile, 'r') as metricsfile_:\n",
    "        row_metrics = json.load(metricsfile_)\n",
    "\n",
    "    # Initialize Metrics (if necessary)\n",
    "    if not metrics_initialized:\n",
    "        metrics_initialized = True\n",
    "        for metric in row_metrics.keys():\n",
    "            metriccolumns.extend([metric + '_kl_div', metric + '_overlap'])\n",
    "    \n",
    "\n",
    "    row = [model, checkpoint, inn, outn, iteration]\n",
    "    # print(row_metrics)\n",
    "    for metric in row_metrics.keys():\n",
    "        [_mean, _std, _kl_div, _overlap, _training_set_kl_div, _training_set_overlap] = row_metrics[metric]\n",
    "        row.extend([ _kl_div, _overlap ])\n",
    "    out.append(row.copy())\n",
    "\n",
    "logfile.close()\n",
    "\n",
    "# Save values to output DF\n",
    "print(pd.DataFrame(out, columns=metriccolumns))\n",
    "df = df_metrics.merge(pd.DataFrame(out, columns=metriccolumns), how='inner', on=['model', 'checkpoint', 'in_len', 'out_len', 'iteration'])\n",
    "\n",
    "df.to_pickle(path.join(outputdir, 'df_metrics'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation fmin which has no identity",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b0cacc23dd97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0mdf_by_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_by_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'overlap_mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'checkpoint'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m     \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_by_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'RdYlGn_r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/seaborn/_decorators.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m             )\n\u001b[1;32m     45\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/seaborn/matrix.py\u001b[0m in \u001b[0;36mheatmap\u001b[0;34m(data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, linewidths, linecolor, cbar, cbar_kws, cbar_ax, square, xticklabels, yticklabels, mask, ax, **kwargs)\u001b[0m\n\u001b[1;32m    535\u001b[0m     plotter = _HeatMapper(data, vmin, vmax, cmap, center, robust, annot, fmt,\n\u001b[1;32m    536\u001b[0m                           \u001b[0mannot_kws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbar_kws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxticklabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m                           yticklabels, mask)\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[0;31m# Add the pcolormesh kwargs here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/seaborn/matrix.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, cbar, cbar_kws, xticklabels, yticklabels, mask)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;31m# Determine good default values for the colormapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         self._determine_cmap_params(plot_data, vmin, vmax,\n\u001b[0;32m--> 156\u001b[0;31m                                     cmap, center, robust)\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;31m# Sort out the annotations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/seaborn/matrix.py\u001b[0m in \u001b[0;36m_determine_cmap_params\u001b[0;34m(self, plot_data, vmin, vmax, cmap, center, robust)\u001b[0m\n\u001b[1;32m    192\u001b[0m                 \u001b[0mvmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanpercentile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m                 \u001b[0mvmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvmax\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrobust\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mnanmin\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/numpy/lib/nanfunctions.py\u001b[0m in \u001b[0;36mnanmin\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;31m# Fast, but not safe for subclasses of ndarray, or object arrays,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;31m# which do not implement isnan (gh-9009), or fmin correctly (gh-8975)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             warnings.warn(\"All-NaN slice encountered\", RuntimeWarning,\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation fmin which has no identity"
     ]
    }
   ],
   "source": [
    "# Plotting phase\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "suffix = '_avg'\n",
    "make_heat_maps = True\n",
    "make_kldiv_plots = True\n",
    "make_overlap_plots = True\n",
    "make_time_plots = True\n",
    "# Read DF\n",
    "df = pd.read_pickle(path.join(outputdir, 'df_metrics'))\n",
    "# df = pd.read_pickle(path.join(outputdir, 'df_metrics_performance_rnn'))\n",
    "\n",
    "# Calculate Mean Values for each in/out len combination\n",
    "df = df.drop(['out_file', 'primer', 'iteration'], axis=1)\n",
    "df = df.groupby(['model', 'checkpoint', 'dataset', 'in_len', 'out_len']).mean()\n",
    "df = df.add_suffix(suffix).reset_index()\n",
    "\n",
    "# Create Fig Folder\n",
    "figdir = 'figs'\n",
    "if not os.path.exists(figdir):\n",
    "    os.mkdir(figdir)\n",
    "\n",
    "# Define which plots to make\n",
    "plots_to_make = (\n",
    "    [ None\n",
    "    # , 'time_heatmap_per_model'\n",
    "    # , 'kldiv_per_model'\n",
    "    # , 'overlap_per_model'\n",
    "    # , 'time_per_length'\n",
    "    # , 'time_ratio_per_length'\n",
    "    # , 'time_per_length_shared' # TODO: Before doing this, check if there's a correlation\n",
    "\n",
    "    # , 'time_per_length_shared'\n",
    "    # , 'parallel_coordinates_all_configs'\n",
    "    # , 'parallel_coordinates_average'\n",
    "    # , 'parallel_coordinates_best_of_each'\n",
    "    # , 'heatmap_metric_per_config'\n",
    "    , 'heatmap_metrics_per_model_config'\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Get in/out len dimensions\n",
    "max_in = max(df['in_len'])\n",
    "max_out = max(df['out_len'])\n",
    "\n",
    "# Get Evaluation Metric Names\n",
    "eval_metrics = ['time' + suffix] + [c for c in list(df.columns) if c.endswith('overlap' + suffix) or c.endswith('kl_div' + suffix)]\n",
    "\n",
    "overlaps = [m for m in eval_metrics if m.endswith('overlap' + suffix)]\n",
    "kl_divs  = [m for m in eval_metrics if m.endswith('kl_div' + suffix)]\n",
    "\n",
    "# Iterate model-checkpoint-dataset tuples\n",
    "grouping = df.groupby(['model', 'checkpoint', 'dataset'])\n",
    "\n",
    "\n",
    "# HeatMaps\n",
    "for (model, checkpoint, dataset), inner_df in grouping:\n",
    "    # inner_df = inner_df.groupby(['in_len', 'out_len'])\n",
    "    if 'time_heatmap_per_model' not in plots_to_make: break\n",
    "    for metric in eval_metrics[:1]:\n",
    "    # for metric in eval_metrics:\n",
    "        mdf = inner_df[['in_len', 'out_len', metric]]\n",
    "        mdf = pd.pivot_table(mdf, values=metric, index=['in_len'], columns=['out_len'], fill_value=0)\n",
    "        plt.figure()\n",
    "        plt.title(f'{metric} - {model} {checkpoint} {dataset}')\n",
    "        # print(sns.heatmap(mdf, cmap='RdYlGn_r', linewidths=0.5, annot=True))\n",
    "        sns.heatmap(mdf, cmap='RdYlGn_r', linewidths=0.5, annot=True)\n",
    "        #plt.pcolor(mdf)\n",
    "        #plt.title(metric)\n",
    "        \n",
    "        plt.savefig(f'{figdir}/time-heatmap-{\"-\".join([model, checkpoint, dataset])}')\n",
    "\n",
    "\n",
    "\n",
    "# make_line_plots\n",
    "plot_sets =[\n",
    "    ('Average Overlaps with Base Dataset', overlaps, 'overlaps'),\n",
    "    ('Average KL-Divergence against Base Dataset', kl_divs, 'kl_divs'),\n",
    "    # ('Average Generation Time', ['time_avg'])\n",
    "]\n",
    "\n",
    "# TODO: Line Plots\n",
    "# How does Input Length affect each metric for a model\n",
    "for (model, checkpoint, dataset), inner_df in grouping:\n",
    "    if 'kldiv_per_model' not in plots_to_make: break\n",
    "    in_len_plot = inner_df.loc[inner_df['out_len'] == max(inner_df['out_len'])]\n",
    "    x = 'in_len'\n",
    "    if not make_kldiv_plots: continue\n",
    "    for title, cols, setname in plot_sets:\n",
    "        fig = plt.figure()\n",
    "        # print(in_len_plot[[x] + cols])\n",
    "        in_len_plot[[x] + cols].plot(x=x, colormap='jet', markersize=10)\n",
    "        plt.title(model)\n",
    "        plt.legend(title=title, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.savefig(f'{figdir}/{\"-\".join([setname, model, checkpoint, dataset])}', bbox_inches='tight')\n",
    "\n",
    "for (model, checkpoint, dataset), inner_df in grouping:\n",
    "    if 'overlap_per_model' not in plots_to_make: break\n",
    "    out_len_plot = inner_df.loc[inner_df['in_len'] == max(inner_df['in_len'])]\n",
    "    x = 'out_len'\n",
    "    if not make_overlap_plots: continue    \n",
    "    for title, cols, setname in plot_sets:\n",
    "        plt.figure()\n",
    "        # print(out_len_plot[[x] + cols])\n",
    "        out_len_plot[[x] + cols].plot(x=x, colormap='jet', markersize=10)\n",
    "        plt.title(model)\n",
    "        plt.legend(title=title, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.savefig(f'{figdir}/{\"-\".join([setname, model, checkpoint, dataset])}', bbox_inches='tight')\n",
    "    \n",
    "# model, checkpoint\n",
    "\n",
    "plots = ['in_len', 'out_len']\n",
    "for l in plots:\n",
    "    if 'metrics_per_each_len' not in plots_to_make: break\n",
    "    cols = ['time_avg']\n",
    "    if not make_time_plots: continue\n",
    "    counterpart = [i for i in plots if i != l][0]\n",
    "    for i in df[counterpart].unique():\n",
    "        time_plot = df.loc[df[counterpart] == i]\n",
    "        time_plot = time_plot[['model', 'checkpoint', l] + cols]\n",
    "        time_plot = pd.pivot_table(time_plot, values=cols, index=[l], columns=['model', 'checkpoint'], fill_value=0)\n",
    "        # print(time_plot)\n",
    "        plt.figure()\n",
    "        time_plot.plot()\n",
    "        plt.legend(title=f'{title} ({counterpart} = {i})', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        # plt.legend(title=f'Average Time for {counterpart} = {i}', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# # TODO: Before doing this, check if there's a correlation\n",
    "# plots = ['in_len', 'out_len']\n",
    "# for l in plots:\n",
    "#     if 'time_per_length_average' not in plots_to_make: break\n",
    "#     cols = ['time_avg']\n",
    "#     if not make_time_plots: continue\n",
    "#     counterpart = [i for i in plots if i != l][0]\n",
    "#     plt.figure()\n",
    "#     for i in df[counterpart].unique():\n",
    "#         time_plot = df.loc[df[counterpart] == i]\n",
    "#         time_plot = time_plot[['model', 'checkpoint', l] + cols]\n",
    "#         time_plot = pd.pivot_table(time_plot, values=cols, index=[l], columns=['model', 'checkpoint'], fill_value=0)\n",
    "#         # print(time_plot)\n",
    "#         time_plot.plot()\n",
    "#         plt.legend(title=f'{title} ({counterpart} = {i})', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "#         # plt.legend(title=f'Average Time for {counterpart} = {i}', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "\n",
    "# Column names to filter out\n",
    "ignore_words = ['std', 'avg', 'kl', 'div', 'overlap']\n",
    "def filter_metric_names(list_):\n",
    "    return ['_'.join([x for x in name.split('_') if x not in ignore_words]) for name in list_]\n",
    "\n",
    "# PLOT: Heatmap By Configuration\n",
    "from matplotlib.colors import LogNorm\n",
    "if 'heatmap_metric_per_config' in plots_to_make:\n",
    "    df_by_config = df.copy()\n",
    "    df_by_config = df_by_config[df_by_config['model'] != 'performance_rnn']\n",
    "    df_by_config['config'] = df_by_config[\"in_len\"].astype(str) + '_' + df_by_config[\"out_len\"].astype(str)\n",
    "    configlen = len(df_by_config['config'].unique())\n",
    "    df_by_config['time_avg'] = df_by_config['time_avg'] / (iterations * configlen)\n",
    "    df_by_config = df_by_config.drop(columns=['in_len','out_len'])\n",
    "    df_by_config = df_by_config.groupby('config')\n",
    "    df_by_config = df_by_config.aggregate('mean')\n",
    "    for i, metricset in enumerate([overlaps, kl_divs]):\n",
    "        a = plt.figure(dpi=150,figsize=(14,10))\n",
    "        inner_df = df_by_config[metricset]\n",
    "        inner_df.columns = filter_metric_names(metricset)\n",
    "        metricset = filter_metric_names(metricset)\n",
    "        sns.heatmap(inner_df[metricset], cmap='Blues', annot=True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'heatmap_{[\"overlaps\",\"kl_divs\"][i]}.png')\n",
    "        plt.show()\n",
    "\n",
    "# Parallel Coordinates Plot\n",
    "from pandas.plotting import parallel_coordinates\n",
    "\n",
    "colors = [ None\n",
    "    , '#2f4b7c'\n",
    "    , '#665191'\n",
    "    , '#a05195'\n",
    "    , '#d45087'\n",
    "    , '#f95d6a'\n",
    "    , '#ff7c43'\n",
    "    , '#ffa600'\n",
    "][1:]\n",
    "\n",
    "colors = [\"#c3839c\", \"#72b2a4\", \"#c9ae89\", \"#c15e5e\", \"#565155\"]\n",
    "\n",
    "# Make KL-Distance / Overlap Multiplot from dataframe\n",
    "from pandas.plotting import parallel_coordinates\n",
    "def make_kl_overlap_multiplot(dataframe,\n",
    "    title=\"No Title\",\n",
    "    label_kl_divs=\"No KL Divs Label\",\n",
    "    label_overlaps=\"No Overlap Label\"):\n",
    "    metricsets = [ None\n",
    "                 , (overlaps, label_overlaps)\n",
    "                 , (kl_divs, label_kl_divs)\n",
    "                 ][1:]\n",
    "\n",
    "    # Create Multiplot\n",
    "    a = plt.figure(dpi=150,figsize=(8,6))\n",
    "    fig, axs = plt.subplots(2, dpi=150,figsize=(10,8),sharex='col', sharey='row')\n",
    "    gs = fig.add_gridspec(2, 1, hspace=0, wspace=0)\n",
    "    plt.suptitle(title)\n",
    "    plt.xticks(rotation=90)\n",
    "\n",
    "    \n",
    "\n",
    "    # Create Subplots\n",
    "    for i, (metricset, legend) in enumerate(metricsets):\n",
    "        \n",
    "        # Prepare Dataframe (Filter Columns)\n",
    "        inner_df = dataframe.copy()\n",
    "        subset_df = inner_df[metricset + ['model']]\n",
    "        subset_df.columns = filter_metric_names(subset_df.columns)\n",
    "        inner_df.columns = filter_metric_names(inner_df.columns)\n",
    "        metricset = filter_metric_names(metricset)\n",
    "\n",
    "        # Calculate plot\n",
    "        final_df = pd.DataFrame(subset_df, columns=metricset)\n",
    "        final_df = pd.concat([final_df, subset_df['model']], axis=1)\n",
    "        # plots.append()\n",
    "        parallel_coordinates(final_df, 'model', colors=colors, ax=axs[i])\n",
    "        axs[i].legend(title=legend, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()\n",
    "\n",
    "    # plt.savefig('test.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Parallel Coordinates: All Configurations\n",
    "if 'parallel_coordinates_all_configs' in plots_to_make:\n",
    "    df_by_config = df.copy()\n",
    "    make_kl_overlap_multiplot(df_by_config\n",
    "    , title=\"Metrics per Model (All Configurations)\"\n",
    "    , label_overlaps=\"Metric KL-Distance per Model\"\n",
    "    , label_kl_divs=\"Metric Overlap per Model\"\n",
    "    )\n",
    "\n",
    "# Parallel Coordinates: Average\n",
    "if 'parallel_coordinates_average' in plots_to_make:\n",
    "    df_by_model = df.copy()\n",
    "    df_by_model = df_by_model.groupby(('model')).mean().reset_index()\n",
    "    make_kl_overlap_multiplot(df_by_model\n",
    "    , title=\"Average Metrics per Model\"\n",
    "    , label_overlaps=\"Average Metric Overlap per Model\"\n",
    "    , label_kl_divs=\"Average Metric KL-Distance per Model\"\n",
    "    )\n",
    "\n",
    "\n",
    "# TODO\n",
    "# Parallel Coordinates (Best of each (ornette) vs baseline)\n",
    "if 'parallel_coordinates_best_of_each' in plots_to_make:\n",
    "    print('')\n",
    "\n",
    "\n",
    "# WIP\n",
    "# Heatmap: Metric mean per config per model\n",
    "if 'heatmap_metrics_per_model_config' in plots_to_make:\n",
    "    # Copy and prepare DataFrame\n",
    "    df_by_config = df.copy()\n",
    "    df_by_config['config'] = df_by_config[\"in_len\"].astype(str) + '_' + df_by_config[\"out_len\"].astype(str)\n",
    "    df_by_config.drop(columns=['in_len','out_len'])\n",
    "    # df_by_config.drop(columns=['in_len','out_len','iteration'])\n",
    "    df_by_config = df_by_config.groupby(['model','checkpoint','config']).mean().reset_index()\n",
    "\n",
    "    # Get Subset DFs\n",
    "    col_metrics = df_by_config.columns\n",
    "    col_kl_divs  = [x for x in col_metrics if x.endswith('kl_div')]\n",
    "    col_overlaps = [x for x in col_metrics if x.endswith('overlap')]\n",
    "\n",
    "    # Calculate KL Divs and Overlap mean and std per model config\n",
    "    loc_kldivs = df_by_config[['model'] + col_kl_divs].loc[: , \"bar_pitch_class_histogram_kl_div\":\"note_length_hist_kl_div\"]\n",
    "    df_by_config['kl_mean'] = loc_kldivs.mean(axis=1)\n",
    "    df_by_config['kl_std'] = loc_kldivs.std(axis=1)\n",
    "    loc_overlaps = df_by_config[['model'] + col_overlaps].loc[: , \"bar_pitch_class_histogram_overlap\":\"note_length_hist_overlap\"]\n",
    "    df_by_config['overlap_mean'] = loc_overlaps.mean(axis=1)\n",
    "    df_by_config['overlap_std'] = loc_overlaps.std(axis=1)\n",
    "    df_by_config = df_by_config[['model','checkpoint','config','overlap_mean','overlap_std','kl_mean','kl_std']]\n",
    "\n",
    "    # Generate Plot\n",
    "    plt.figure()\n",
    "    # df_by_config = pd.pivot_table(df_by_config, values=['overlap_mean','overlap_std','kl_mean','kl_std'], index=['config'], columns=['model'])\n",
    "    df_by_config = pd.pivot_table(df_by_config, values=['overlap_mean'], index=['config'], columns=['model', 'checkpoint'])\n",
    "\n",
    "    print(df_by_config)\n",
    "\n",
    "    sns.heatmap(df_by_config, cmap='RdYlGn_r', linewidths=0.5, annot=True)\n",
    "    plt.savefig('test.png')\n",
    "    plt.show()\n",
    "\n",
    "print(f'Done! Generated plots: {plots_to_make}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(df)\n",
    "# print(output)\n",
    "# print(a_test)\n",
    "# print(cols_gen)\n",
    "# cols_gen = [ \"model\", \"checkpoint\", \"dataset\", \"primer\", \"iteration\", \"out_file\", \"time\", \"in_len\", \"out_len\" ]\n",
    "\n",
    "# a_test = pd.DataFrame(output, columns=cols_gen)\n",
    "# a_test.head()\n",
    "# a_test.to_pickle('./output/temp_rl_df')\n",
    "print(output)"
   ]
  }
 ]
}